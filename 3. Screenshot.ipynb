{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, ComplementNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.base import TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8803827751196173\n",
      "[[0.84848485 0.         0.09090909 0.06060606 0.         0.        ]\n",
      " [0.         1.         0.         0.         0.         0.        ]\n",
      " [0.01538462 0.         0.98461538 0.         0.         0.        ]\n",
      " [0.03846154 0.         0.07692308 0.76923077 0.         0.11538462]\n",
      " [0.04761905 0.         0.23809524 0.14285714 0.57142857 0.        ]\n",
      " [0.         0.         0.08510638 0.         0.         0.91489362]]\n",
      "0.8803827751196173\n",
      "[[0.90909091 0.         0.03030303 0.06060606 0.         0.        ]\n",
      " [0.         1.         0.         0.         0.         0.        ]\n",
      " [0.01538462 0.         0.95384615 0.         0.         0.03076923]\n",
      " [0.03846154 0.         0.03846154 0.76923077 0.03846154 0.11538462]\n",
      " [0.28571429 0.         0.         0.14285714 0.57142857 0.        ]\n",
      " [0.         0.         0.06382979 0.         0.         0.93617021]]\n",
      "0.8899521531100478\n",
      "[[0.84848485 0.         0.03030303 0.06060606 0.06060606 0.        ]\n",
      " [0.         1.         0.         0.         0.         0.        ]\n",
      " [0.01538462 0.         0.87692308 0.03076923 0.01538462 0.06153846]\n",
      " [0.03846154 0.         0.03846154 0.80769231 0.         0.11538462]\n",
      " [0.04761905 0.         0.         0.         0.95238095 0.        ]\n",
      " [0.         0.         0.08510638 0.         0.         0.91489362]]\n"
     ]
    }
   ],
   "source": [
    "#algorithm\n",
    "class todense(TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        return X.toarray()\n",
    "\n",
    "\n",
    "# load data\n",
    "df_transactions = pd.read_csv('DataSet.csv', sep=\";\", header=0)\n",
    "\n",
    "# format numbers\n",
    "X = []\n",
    "for num in df_transactions['Betrag']:\n",
    "    X.append(num.replace(\",\", \".\"))\n",
    "df_transactions['Betrag'] = X\n",
    "X = 0\n",
    "\n",
    "# set data types\n",
    "df_transactions['Verwendungszweck'] = \n",
    "                        df_transactions['Verwendungszweck'].astype('str')\n",
    "df_transactions['label'] = df_transactions['label'].astype(\"category\")\n",
    "verwendungszweck = df_transactions[\"Verwendungszweck\"].tolist()\n",
    "\n",
    "# data cleaning/ preprocessing\n",
    "my_stopword_list = [\"and\", \"to\", \"the\", \"of\", \"notprovided\"]\n",
    "rowAdapted = []\n",
    "for row in verwendungszweck:\n",
    "    sentence = row.lower()\n",
    "    sentence = re.sub(\"[0-9]+\", \" \", sentence)\n",
    "    word = re.findall(r'\\w+', sentence)\n",
    "    if len(sentence) > 1 and not(len(row) == 0):\n",
    "        if sentence not in my_stopword_list: \n",
    "            rowAdapted.append(word)\n",
    "verwendungszweck = rowAdapted\n",
    "\n",
    "# Prediction\n",
    "# MultinomialNB\n",
    "clf_pipe_MNB = Pipeline([(\"vectorizer\", TfidfVectorizer(analyzer=lambda x:x)),\n",
    "                         (\"clf\", MultinomialNB())])\n",
    "# ComplementNB\n",
    "clf_pipe_CNB = Pipeline([(\"vectorizer\", TfidfVectorizer(analyzer=lambda x:x)),\n",
    "                         (\"clf\", ComplementNB())])\n",
    "# GaussianNB\n",
    "clf_pipe_GNB = Pipeline([(\"vectorizer\", TfidfVectorizer(analyzer=lambda x:x)),\n",
    "                         (\"todense\", todense()), (\"clf\", GaussianNB())])\n",
    "\n",
    "clf_models = [clf_pipe_MNB, clf_pipe_CNB, clf_pipe_GNB]\n",
    "X_train = verwendungszweck\n",
    "y_train = df_transactions[\"label\"]\n",
    "\n",
    "for i in range(0, len(clf_models)):\n",
    "    models = clf_models[i]\n",
    "    if i < 2:\n",
    "        parameters = {\"clf__alpha\": (2, 1e-2, 1e-3, 1e-4, 1e-5)}\n",
    "        gridsearch_multi = GridSearchCV(models, parameters, iid= True, cv=5)\n",
    "        fitter = gridsearch_multi.fit(X_train, y_train)\n",
    "\n",
    "    else:\n",
    "        parameters = {}\n",
    "        gridsearch_multi = GridSearchCV(models, parameters, iid = True, cv=5)\n",
    "        fitter = gridsearch_multi.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = cross_val_predict(gridsearch_multi, X_train, y_train, cv=5)\n",
    "    cm = confusion_matrix(y_train, y_pred)\n",
    "    cm2 = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    # printing results\n",
    "    print(fitter.best_score_)\n",
    "    print(cm2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
